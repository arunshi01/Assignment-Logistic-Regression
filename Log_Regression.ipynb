{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP92JVegZ8stiZo9HgHXDPn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunshi01/Assignment-Logistic-Regression/blob/main/Log_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?\n",
        "\n",
        "\n",
        "Logistic Regression\n",
        "\n",
        "-Logistic Regression is a statistical and machine learning method used for classification problems (predicting categories like yes/no, spam/not spam, 0/1).\n",
        "\n",
        "-It predicts the probability that an observation belongs to a certain class.\n",
        "\n",
        "-Instead of fitting a straight line, it uses the logistic (sigmoid) function to squash outputs between 0 and 1.\n",
        "\n",
        "\n",
        "Linear Regression\n",
        "\n",
        "-Linear Regression is used for regression problems (predicting continuous values like salary, house price, temperature).\n",
        "\n",
        "-It fits a straight line (y = Œ≤0 + Œ≤1X) to predict values.\n",
        "\n",
        "-Output can be any real number (‚àí‚àû to +‚àû), not restricted to 0‚Äì1.\n",
        "\n",
        "In short: Linear Regression predicts ‚Äúhow much‚Äù, Logistic Regression predicts ‚Äúwhich class (yes/no)‚Äù."
      ],
      "metadata": {
        "id": "39z2DzYt-0dJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2- Explain the role of the Sigmoid function in Logistic Regression.\n",
        "\n",
        "The sigmoid function transforms linear outputs into probabilities, which is the reason Logistic Regression can classify outcomes.\n",
        "\n",
        "-It takes any real-valued number ùëß z (from ‚àí‚àû to +‚àû)\n",
        "\n",
        "-Squashes it into a range between 0 and 1ole in Logistic.\n",
        "\n",
        "**Role in Logistic Regression**\n",
        "\n",
        "-The linear part (ùõΩ0+ùõΩ1x) gives an unrestricted value.\n",
        "\n",
        "-The sigmoid converts this value into a probability.\n",
        "\n",
        "So the model becomes:\n",
        "\n",
        "If probability > 0.5 ‚Üí Predict class 1\n",
        "\n",
        "If probability ‚â§ 0.5 ‚Üí Predict class 0"
      ],
      "metadata": {
        "id": "171vkcN9_nOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "\n",
        "Regularization is a technique used in Logistic Regression (and other ML models) to prevent overfitting by adding a penalty term to the cost function.\n",
        "\n",
        "**Why is Regularization Needed?**\n",
        "\n",
        "i)Prevents Overfitting-If the model has too many features, it might ‚Äúmemorize‚Äù training data instead of learning general patterns. Regularization keeps coefficients small, forcing the model to stay simple.\n",
        "\n",
        "ii)Improves Generalization-Helps the model perform better on unseen data.\n",
        "\n",
        "iii)Handles Multicollinearity-By shrinking coefficients, it reduces instability when features are highly correlated.\n",
        "\n",
        "iv)Feature Selection (L1)-Lasso (L1) can shrink some coefficients to zero, effectively removing irrelevant features."
      ],
      "metadata": {
        "id": "UP2m2oD3CHC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4- What are some common evaluation metrics for classification models, and why are they important?\n",
        "\n",
        "1. Accuracy\n",
        "Measures the overall correctness of the model.\n",
        "Good when classes are balanced, but misleading if data is imbalanced.\n",
        "\n",
        "2. Precision\n",
        "Out of all predicted positives, how many were actually positive.\n",
        "Important when false positives are costly (e.g., spam detection).\n",
        "\n",
        "3. Recall (Sensitivity or True Positive Rate)\n",
        "Out of all actual positives, how many did the model correctly identify.\n",
        "Important when false negatives are costly (e.g., disease detection).\n",
        "\n",
        "4. F1-Score\n",
        "Harmonic mean of Precision and Recall.\n",
        "Useful when you need a balance between Precision and Recall, especially with imbalanced datasets.\n",
        "\n",
        "5. ROC Curve & AUC (Area Under Curve)\n",
        "ROC Curve ‚Üí plots True Positive Rate vs. False Positive Rate at different thresholds.\n",
        "AUC ‚Üí measures the model‚Äôs ability to separate classes.\n",
        "Higher AUC (close to 1) = better classifier.\n",
        "\n",
        "6. Confusion Matrix\n",
        "A table showing TP, TN, FP, FN.\n",
        "Helps visualize where the model is making mistakes.\n",
        "\n",
        "**Why They Are Important**\n",
        "\n",
        "i)Different problems care about different types of errors.\n",
        "\n",
        "Example:\n",
        "In fraud detection, recall is crucial (catch all fraud cases).\n",
        "In email spam filtering, precision matters more (don‚Äôt mark important emails as spam).\n",
        "\n",
        "ii)Metrics help us choose the right model and tune thresholds for the actual business goal."
      ],
      "metadata": {
        "id": "ciFUjRw0DGm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "(Use Dataset from sklearn package)\n"
      ],
      "metadata": {
        "id": "X2scG2-NExDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset from sklearn\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target  # Add target column\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split into train and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=5000)  # Increased iterations for convergence\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Logistic Regression Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoZUDhXIFO3m",
        "outputId": "16c98648-48b8-4e8c-98f3-d8ba9180be59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Model Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program to train a Logistic Regression model using L2\n",
        "regularization (Ridge) and print the model coefficients and accuracy.\n"
      ],
      "metadata": {
        "id": "1inmwqEMFgSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression with L2 regularization (default = 'l2')\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=5000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Logistic Regression with L2 Regularization Accuracy:\", accuracy)\n",
        "\n",
        "# Model Coefficients\n",
        "print(\"\\nModel Coefficients:\")\n",
        "for feature, coef in zip(X.columns, model.coef_[0]):\n",
        "    print(f\"{feature}: {coef}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0txG6V-SFhd5",
        "outputId": "d911a490-d6e5-42bc-9808-4bd4ed484138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression with L2 Regularization Accuracy: 0.956140350877193\n",
            "\n",
            "Model Coefficients:\n",
            "mean radius: 1.027436803336593\n",
            "mean texture: 0.2214505054000141\n",
            "mean perimeter: -0.36213488380572045\n",
            "mean area: 0.0254667014198235\n",
            "mean smoothness: -0.156235324092095\n",
            "mean compactness: -0.23771255545593115\n",
            "mean concavity: -0.5325578605476696\n",
            "mean concave points: -0.28369224421619993\n",
            "mean symmetry: -0.22668188523846416\n",
            "mean fractal dimension: -0.036494462364261356\n",
            "radius error: -0.09710207615387977\n",
            "texture error: 1.3705666970168586\n",
            "perimeter error: -0.1814094222040424\n",
            "area error: -0.08719574741768957\n",
            "smoothness error: -0.02245523103377289\n",
            "compactness error: 0.047360921809598944\n",
            "concavity error: -0.04294784123303201\n",
            "concave points error: -0.03240188144834079\n",
            "symmetry error: -0.034737324074110565\n",
            "fractal dimension error: 0.011605215226101482\n",
            "worst radius: 0.1116532864925189\n",
            "worst texture: -0.5088772244264381\n",
            "worst perimeter: -0.015553947678909089\n",
            "worst area: -0.01685699621166072\n",
            "worst smoothness: -0.30773116939737566\n",
            "worst compactness: -0.7727090806929424\n",
            "worst concavity: -1.4285953527054682\n",
            "worst concave points: -0.5109292290698249\n",
            "worst symmetry: -0.7468936332136408\n",
            "worst fractal dimension: -0.10094403812918722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report.\n",
        "(Use Dataset from sklearn package"
      ],
      "metadata": {
        "id": "kjoclMn2F7rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load Iris dataset\n",
        "data = load_iris()\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Logistic Regression with One-vs-Rest\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=5000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report (One-vs-Rest Logistic Regression):\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g2bWE6NGOxp",
        "outputId": "739a9381-52f2-4611-e98b-8af72b74cb60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (One-vs-Rest Logistic Regression):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      0.80      0.89        10\n",
            "   virginica       0.83      1.00      0.91        10\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.94      0.93      0.93        30\n",
            "weighted avg       0.94      0.93      0.93        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "accuracy"
      ],
      "metadata": {
        "id": "2Y-axb5yGWHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Define Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=5000, solver='liblinear')\n",
        "# 'liblinear' supports both l1 and l2 penalties\n",
        "\n",
        "# Define parameter grid for C and penalty\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],      # Regularization strength\n",
        "    'penalty': ['l1', 'l2']            # L1 (Lasso), L2 (Ridge)\n",
        "}\n",
        "\n",
        "# GridSearchCV with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Best cross-validation accuracy\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy with Best Parameters:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeMtD2duGkeq",
        "outputId": "ccd1e769-a0ce-4891-e3d1-dd0892714bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1'}\n",
            "Best Cross-Validation Accuracy: 0.9666666666666668\n",
            "Test Accuracy with Best Parameters: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling.\n"
      ],
      "metadata": {
        "id": "5DQiEFf9Goe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -------------------\n",
        "# 1. Logistic Regression WITHOUT scaling\n",
        "# -------------------\n",
        "model_no_scaling = LogisticRegression(max_iter=5000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# -------------------\n",
        "# 2. Logistic Regression WITH scaling\n",
        "# -------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaling = LogisticRegression(max_iter=5000)\n",
        "model_scaling.fit(X_train_scaled, y_train)\n",
        "y_pred_scaling = model_scaling.predict(X_test_scaled)\n",
        "accuracy_scaling = accuracy_score(y_test, y_pred_scaling)\n",
        "\n",
        "# -------------------\n",
        "# Results\n",
        "# -------------------\n",
        "print(\"Accuracy WITHOUT Scaling:\", accuracy_no_scaling)\n",
        "print(\"Accuracy WITH Scaling:\", accuracy_scaling)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdDy0Fm4Gug8",
        "outputId": "ee493c03-99db-4247-e373-684c6658be83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy WITHOUT Scaling: 0.9649122807017544\n",
            "Accuracy WITH Scaling: 0.9824561403508771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you are working at an e-commerce company that wants to\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you‚Äôd  take to build a Logistic Regression model ‚Äî including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\n",
        "\n",
        "\n",
        "1. Problem Understanding\n",
        "\n",
        "-Goal ‚Üí Predict if a customer will respond (Yes/No).\n",
        "-Challenge ‚Üí Highly imbalanced dataset (5% positive responses vs 95% no response).\n",
        "-Impact ‚Üí Misclassifying responders (false negatives) is costlier than predicting some non-responders wrongly.\n",
        "\n",
        "2. Data Handling\n",
        "-Collect features: demographics, browsing history, purchase history, engagement with past campaigns, etc.\n",
        "-Data cleaning: handle missing values, encode categorical features (e.g., one-hot or target encoding).\n",
        "-Feature engineering:\n",
        "Aggregate features (e.g., total spend in last 6 months).\n",
        "Interaction features (e.g., product category √ó last login frequency).\n",
        "\n",
        "3. Feature Scaling\n",
        "-Logistic Regression is sensitive to different feature scales.\n",
        "-Apply StandardScaler (mean = 0, std = 1) or MinMaxScaler to ensure features are comparable.\n",
        "\n",
        "4. Balancing Classes\n",
        "Since only 5% respond ‚Üí highly imbalanced. Options:\n",
        "-Class weights: Use class_weight='balanced' in Logistic Regression(recommended).\n",
        "-Resampling:\n",
        "  -Oversample minority (SMOTE, RandomOverSampler).\n",
        "  -Undersample majority (RandomUnderSampler).\n",
        "-Hybrid approach: SMOTE + undersampling.\n",
        "\n",
        "5. Hyperparameter Tuning\n",
        "-Use GridSearchCV or RandomizedSearchCV to tune:\n",
        "C (regularization strength).\n",
        "penalty (L1, L2).\n",
        "solver (liblinear, saga).\n",
        "-Evaluate using stratified cross-validation to preserve class balance in folds.\n",
        "\n",
        "6. Evaluation Metrics\n",
        "-Accuracy is misleading (predicting all \"No\" gives 95% accuracy).\n",
        "-Use metrics for imbalanced classification:\n",
        " Precision, Recall, F1-score ‚Üí especially recall (don‚Äôt miss responders).\n",
        " ROC-AUC ‚Üí overall class separation.\n",
        " PR-AUC (Precision-Recall curve) ‚Üí more informative when positives are rare.\n",
        "-Business context ‚Üí may favor high recall (catch more responders) even at the cost of some false positives.\n",
        "\n",
        "7. Model Interpretation\n",
        "-Logistic Regression provides coefficients ‚Üí odds ratios.\n",
        "-Can help marketing team understand which features drive response (e.g., ‚Äúrecent buyers are 3x more likely to respond‚Äù).\n",
        "\n",
        "8. Deployment & Monitoring\n",
        "-Deploy best model ‚Üí predict which customers to target.\n",
        "-Monitor metrics over time (class distribution may drift).\n",
        "-Re-train periodically with new campaign data.\n",
        "\n",
        "**Final Approach (Summary):**\n",
        "\n",
        "Clean & preprocess data, encode categorical features.\n",
        "\n",
        "Scale features (StandardScaler).\n",
        "\n",
        "Handle imbalance using class_weight='balanced' (and possibly SMOTE).\n",
        "\n",
        "Tune C and penalty with GridSearchCV.\n",
        "\n",
        "Evaluate using F1-score, Recall, ROC-AUC, and PR-AUC (not accuracy).\n",
        "\n",
        "Interpret coefficients for business insights.\n",
        "\n",
        "Deploy, monitor, and retrain regularly."
      ],
      "metadata": {
        "id": "DkJ_JsfaG3Nz"
      }
    }
  ]
}